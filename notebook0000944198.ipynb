{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11045637,"sourceType":"datasetVersion","datasetId":6880582},{"sourceId":11045665,"sourceType":"datasetVersion","datasetId":6880600}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\n# Load data\nreports = pd.read_csv(\"/kaggle/input/tcga-pathology-reports/TCGA_Reports.csv\")\nlabels = pd.read_csv(\"/kaggle/input/tcga-patient-to-cancer-type/tcga_patient_to_cancer_type.csv\")\n\n# Extract patient_id from patient_filename using the TCGA ID pattern\nreports['patient_id'] = reports['patient_filename'].str.extract(r'(TCGA-\\w+-\\w+)', expand=False)\n\n# Merge reports with labels\ndata = pd.merge(reports, labels, on=\"patient_id\", how='inner')\n\n# Clean text: lowercase, remove non-alphanumeric characters, and extra spaces\ndata[\"clean_text\"] = data[\"text\"].str.lower().replace(r'[^a-z0-9\\s]', '', regex=True).replace(r'\\s+', ' ', regex=True)\n\n# Encode labels\nle = LabelEncoder()\ndata[\"label\"] = le.fit_transform(data[\"cancer_type\"])\n\n# Split data (80% train, 10% val, 10% test)\ntrain_df, temp_df = train_test_split(data, test_size=0.2, stratify=data[\"label\"], random_state=42)\nval_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df[\"label\"], random_state=42)\n\n# Print dataset sizes\nprint(f\"Training set: {len(train_df)} samples\")\nprint(f\"Validation set: {len(val_df)} samples\")\nprint(f\"Test set: {len(test_df)} samples\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T02:48:44.582567Z","iopub.execute_input":"2025-03-19T02:48:44.582740Z","iopub.status.idle":"2025-03-19T02:48:47.894730Z","shell.execute_reply.started":"2025-03-19T02:48:44.582723Z","shell.execute_reply":"2025-03-19T02:48:47.893918Z"}},"outputs":[{"name":"stdout","text":"Training set: 7618 samples\nValidation set: 952 samples\nTest set: 953 samples\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import f1_score, classification_report\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV\n\n# Create a pipeline\npipeline = Pipeline([\n    ('tfidf', TfidfVectorizer(\n        max_features=10000,  # Increased from 5000\n        ngram_range=(1, 3),  # Added trigrams\n        min_df=2,  # Remove very rare terms\n        max_df=0.95,  # Remove very common terms\n        stop_words='english'  # Remove stopwords\n    )),\n    ('scaler', StandardScaler(with_mean=False)),  # Scale features\n    ('clf', LogisticRegression(\n        max_iter=1000,\n        class_weight='balanced',  # Handle class imbalance\n        multi_class='ovr',  # One-vs-rest strategy\n        solver='liblinear'\n    ))\n])\n\n# Define parameter grid for GridSearchCV\nparam_grid = {\n    'clf__C': [0.01, 0.1, 1.0, 10.0],\n    'tfidf__max_features': [10000, 15000],\n    'tfidf__ngram_range': [(1, 2), (1, 3)]\n}\n\n# Perform grid search\ngrid_search = GridSearchCV(\n    pipeline,\n    param_grid,\n    cv=5,\n    scoring='f1_weighted',\n    n_jobs=-1,\n    verbose=1\n)\n\n# Fit the model\ngrid_search.fit(train_df[\"clean_text\"], train_df[\"label\"])\n\n# Get best parameters\nprint(\"Best parameters:\", grid_search.best_params_)\n\n# Make predictions\nval_preds = grid_search.predict(val_df[\"clean_text\"])\ntest_preds = grid_search.predict(test_df[\"clean_text\"])\n\n# Print results\nprint(\"\\nValidation F1:\", f1_score(val_df[\"label\"], val_preds, average=\"weighted\"))\nprint(\"Test F1:\", f1_score(test_df[\"label\"], test_preds, average=\"weighted\"))\nprint(\"\\nDetailed Classification Report:\")\nprint(classification_report(\n    test_df[\"label\"],\n    test_preds,\n    target_names=le.classes_,\n    zero_division=0\n))\n\n# Print performance analysis for rare classes\nprint(\"\\nPerformance analysis for classes with low support:\")\nfor idx, label in enumerate(le.classes_):\n    support = (test_df[\"label\"] == idx).sum()\n    if support < 15:  # Focus on rare classes\n        print(f\"\\nClass {label}:\")\n        print(f\"Support: {support} samples\")\n        print(f\"Predictions made: {(test_preds == idx).sum()} times\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T02:48:47.895425Z","iopub.execute_input":"2025-03-19T02:48:47.895591Z","iopub.status.idle":"2025-03-19T03:02:01.983775Z","shell.execute_reply.started":"2025-03-19T02:48:47.895576Z","shell.execute_reply":"2025-03-19T03:02:01.982800Z"}},"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 16 candidates, totalling 80 fits\nBest parameters: {'clf__C': 0.1, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 2)}\n\nValidation F1: 0.9542258876559221\nTest F1: 0.9652012539545927\n\nDetailed Classification Report:\n              precision    recall  f1-score   support\n\n         ACC       1.00      0.89      0.94         9\n        BLCA       1.00      1.00      1.00        38\n        BRCA       1.00      1.00      1.00       104\n        CESC       0.90      0.97      0.93        29\n        CHOL       1.00      1.00      1.00         4\n        COAD       0.93      1.00      0.97        42\n        DLBC       1.00      1.00      1.00         4\n        ESCA       1.00      0.87      0.93        15\n         GBM       0.98      1.00      0.99        40\n        HNSC       1.00      0.98      0.99        52\n        KICH       0.85      1.00      0.92        11\n        KIRC       0.96      0.94      0.95        53\n        KIRP       0.96      0.93      0.95        28\n         LGG       0.98      0.98      0.98        47\n        LIHC       1.00      1.00      1.00        34\n        LUAD       0.87      0.92      0.89        49\n        LUSC       0.87      0.85      0.86        47\n        MESO       1.00      1.00      1.00         8\n          OV       0.97      0.95      0.96        37\n        PAAD       1.00      1.00      1.00        18\n        PCPG       0.95      1.00      0.97        18\n        PRAD       1.00      1.00      1.00        45\n        READ       1.00      0.81      0.90        16\n        SARC       1.00      0.92      0.96        25\n        SKCM       1.00      0.80      0.89        10\n        STAD       0.95      1.00      0.97        36\n        TGCT       1.00      1.00      1.00         8\n        THCA       1.00      1.00      1.00        49\n        THYM       1.00      1.00      1.00        11\n        UCEC       0.95      0.98      0.96        55\n         UCS       1.00      0.80      0.89         5\n         UVM       1.00      1.00      1.00         6\n\n    accuracy                           0.97       953\n   macro avg       0.97      0.96      0.96       953\nweighted avg       0.97      0.97      0.97       953\n\n\nPerformance analysis for classes with low support:\n\nClass ACC:\nSupport: 9 samples\nPredictions made: 8 times\n\nClass CHOL:\nSupport: 4 samples\nPredictions made: 4 times\n\nClass DLBC:\nSupport: 4 samples\nPredictions made: 4 times\n\nClass KICH:\nSupport: 11 samples\nPredictions made: 13 times\n\nClass MESO:\nSupport: 8 samples\nPredictions made: 8 times\n\nClass SKCM:\nSupport: 10 samples\nPredictions made: 8 times\n\nClass TGCT:\nSupport: 8 samples\nPredictions made: 8 times\n\nClass THYM:\nSupport: 11 samples\nPredictions made: 11 times\n\nClass UCS:\nSupport: 5 samples\nPredictions made: 4 times\n\nClass UVM:\nSupport: 6 samples\nPredictions made: 6 times\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install transformers datasets accelerate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T03:02:01.984622Z","iopub.execute_input":"2025-03-19T03:02:01.984912Z","iopub.status.idle":"2025-03-19T03:02:06.773636Z","shell.execute_reply.started":"2025-03-19T03:02:01.984886Z","shell.execute_reply":"2025-03-19T03:02:06.772687Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.3.1)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.2.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.12)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\nRequirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.1+cu121)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\nimport torch\n\n# Load ClinicalBERT\nmodel_name = \"emilyalsentzer/Bio_ClinicalBERT\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(le.classes_))\n\n# Tokenize text with reduced max_length\ntrain_encodings = tokenizer(train_df[\"clean_text\"].tolist(), truncation=True, padding=True, max_length=128)\nval_encodings = tokenizer(val_df[\"clean_text\"].tolist(), truncation=True, padding=True, max_length=128)\ntest_encodings = tokenizer(test_df[\"clean_text\"].tolist(), truncation=True, padding=True, max_length=128)\n\n# Convert to PyTorch datasets\nclass CustomDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item[\"labels\"] = torch.tensor(self.labels[idx])\n        return item\n    def __len__(self):\n        return len(self.labels)\n\ntrain_dataset = CustomDataset(train_encodings, train_df[\"label\"].tolist())\nval_dataset = CustomDataset(val_encodings, val_df[\"label\"].tolist())\ntest_dataset = CustomDataset(test_encodings, test_df[\"label\"].tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T03:02:06.774557Z","iopub.execute_input":"2025-03-19T03:02:06.774780Z","iopub.status.idle":"2025-03-19T03:02:40.500041Z","shell.execute_reply.started":"2025-03-19T03:02:06.774762Z","shell.execute_reply":"2025-03-19T03:02:40.499461Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54a18b3345cd4a80bf36e378fb150c19"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91c116c1ea454dd9aab69e1459da606a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/436M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0d1a857a05f4cf8bc87dc4a39032ba7"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Training arguments (optimized for Google Colab GPU)\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    eval_strategy=\"epoch\",\n    learning_rate=3e-5,  # Keep this - it's optimal for ClinicalBERT\n    per_device_train_batch_size=16,  # Increased from 8 for faster training\n    per_device_eval_batch_size=16,   # Increased to match train batch size\n    num_train_epochs=1,  # Reduced from 4 to save time while maintaining performance\n    weight_decay=0.01,\n    logging_dir=\"./logs\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    metric_for_best_model=\"f1\",\n    report_to=\"none\",\n    fp16=True,\n    gradient_accumulation_steps=2,  # Added to compensate for larger batch size\n    warmup_steps=100,              # Added for better training stability\n)\n\n# Keep the rest of your code the same\ndef compute_metrics(pred):\n    labels = pred.label_ids\n    preds = pred.predictions.argmax(-1)\n    f1 = f1_score(labels, preds, average='weighted')\n    return {\n        'f1': f1,\n    }\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    compute_metrics=compute_metrics,\n)\n\n# Train and save\ntrainer.train()\ntrainer.save_model(\"clinicalbert_finetuned\")\n\n# Evaluate on test set\ntest_results = trainer.evaluate(test_dataset)\nprint(\"\\nTest Results:\", test_results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T03:02:40.501652Z","iopub.execute_input":"2025-03-19T03:02:40.502154Z","iopub.status.idle":"2025-03-19T04:03:34.826236Z","shell.execute_reply.started":"2025-03-19T03:02:40.502134Z","shell.execute_reply":"2025-03-19T04:03:34.825169Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='238' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [238/238 58:24, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>No log</td>\n      <td>0.909792</td>\n      <td>0.791058</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"\nTest Results: {'eval_loss': 0.8658546805381775, 'eval_f1': 0.8108688542522959, 'eval_runtime': 133.1326, 'eval_samples_per_second': 7.158, 'eval_steps_per_second': 0.451, 'epoch': 0.9979035639412998}\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Predict on test set\ntest_preds = trainer.predict(test_dataset)\npredicted_labels = test_preds.predictions.argmax(-1)\n\n# Calculate F1\ntest_f1 = f1_score(test_df[\"label\"], predicted_labels, average=\"weighted\")\nprint(f\"ClinicalBERT Test F1: {test_f1:.4f}\")\nprint(classification_report(test_df[\"label\"], predicted_labels, target_names=le.classes_))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T04:03:34.828140Z","iopub.execute_input":"2025-03-19T04:03:34.828370Z","iopub.status.idle":"2025-03-19T04:05:43.874002Z","shell.execute_reply.started":"2025-03-19T04:03:34.828351Z","shell.execute_reply":"2025-03-19T04:05:43.872900Z"}},"outputs":[{"name":"stdout","text":"ClinicalBERT Test F1: 0.8109\n              precision    recall  f1-score   support\n\n         ACC       0.00      0.00      0.00         9\n        BLCA       0.95      1.00      0.97        38\n        BRCA       0.99      0.98      0.99       104\n        CESC       1.00      0.76      0.86        29\n        CHOL       0.00      0.00      0.00         4\n        COAD       0.72      0.98      0.83        42\n        DLBC       0.00      0.00      0.00         4\n        ESCA       1.00      0.47      0.64        15\n         GBM       1.00      0.88      0.93        40\n        HNSC       0.98      0.94      0.96        52\n        KICH       0.00      0.00      0.00        11\n        KIRC       0.56      0.98      0.71        53\n        KIRP       0.00      0.00      0.00        28\n         LGG       0.87      1.00      0.93        47\n        LIHC       0.87      0.97      0.92        34\n        LUAD       0.70      0.86      0.77        49\n        LUSC       0.80      0.79      0.80        47\n        MESO       1.00      0.75      0.86         8\n          OV       0.90      0.76      0.82        37\n        PAAD       0.81      0.94      0.87        18\n        PCPG       0.73      0.89      0.80        18\n        PRAD       0.98      0.98      0.98        45\n        READ       1.00      0.12      0.22        16\n        SARC       1.00      0.60      0.75        25\n        SKCM       0.83      1.00      0.91        10\n        STAD       0.80      0.97      0.88        36\n        TGCT       1.00      0.88      0.93         8\n        THCA       0.94      1.00      0.97        49\n        THYM       1.00      0.91      0.95        11\n        UCEC       0.69      0.96      0.80        55\n         UCS       0.00      0.00      0.00         5\n         UVM       1.00      0.67      0.80         6\n\n    accuracy                           0.84       953\n   macro avg       0.72      0.69      0.68       953\nweighted avg       0.81      0.84      0.81       953\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import re\nimport pandas as pd\n\n# Define rules with case-insensitive regex\naugmentation_rules = {\n    \"squamous cell\": \"epidermoid carcinoma\",\n    \"adenocarcinoma\": \"glandular cancer\",\n    \"carcinoma\": \"malignant neoplasm\",\n}\n\ndef augment_text(text):\n    if pd.isna(text):\n        return text\n    for term, replacement in augmentation_rules.items():\n        # Case-insensitive, whole-word replacement\n        text = re.sub(rf\"(?i)\\b{re.escape(term)}\\b\", replacement, text)\n    return text\n\n# Fill NaN values\ntrain_df[\"clean_text\"] = train_df[\"clean_text\"].fillna(\"\")\n\n# Apply augmentation\ntrain_df[\"augmented_text\"] = train_df[\"clean_text\"].apply(augment_text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T04:05:43.875267Z","iopub.execute_input":"2025-03-19T04:05:43.875546Z","iopub.status.idle":"2025-03-19T04:05:45.333298Z","shell.execute_reply.started":"2025-03-19T04:05:43.875514Z","shell.execute_reply":"2025-03-19T04:05:45.332291Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import pandas as pd\nfrom transformers import Trainer, TrainingArguments\nfrom sklearn.metrics import f1_score\nimport numpy as np\n\n# 1. Combine original and augmented data\naugmented_train_df = pd.concat([train_df, train_df.copy()], ignore_index=True)\n\n# 2. Handle NaN values in augmented_text\naugmented_train_df[\"augmented_text\"] = augmented_train_df[\"augmented_text\"].fillna(\"\")\n\n# 3. Tokenize augmented data\naugmented_train_encodings = tokenizer(\n    augmented_train_df[\"augmented_text\"].tolist(), \n    truncation=True, \n    padding=True, \n    max_length=256\n)\n\n# 4. Define CustomDataset\nclass CustomDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item[\"labels\"] = torch.tensor(self.labels[idx])\n        return item\n    def __len__(self):\n        return len(self.labels)\n\naugmented_train_dataset = CustomDataset(augmented_train_encodings, augmented_train_df[\"label\"].tolist())\n\n# 5. Define TrainingArguments with eval_f1 tracking\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    run_name=\"clinicalbert-augmented-v1\",  # Custom run name\n    eval_strategy=\"epoch\",\n    learning_rate=3e-5,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    num_train_epochs=4,\n    weight_decay=0.01,\n    metric_for_best_model=\"eval_f1\",\n    greater_is_better=True,\n    logging_dir=\"./logs\",\n    report_to=\"wandb\",  # Explicitly enable wandb (optional)\n)\n\n# 6. Initialize Trainer with compute_metrics\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=augmented_train_dataset,\n    eval_dataset=val_dataset,\n    compute_metrics=compute_metrics,\n)\n\n# 7. Train and Evaluate\ntrainer.train()\ntest_preds = trainer.predict(test_dataset)\nprint(f\"Augmented ClinicalBERT F1: {f1_score(test_df['label'], test_preds.predictions.argmax(-1), average='weighted'):.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T04:05:45.334191Z","iopub.execute_input":"2025-03-19T04:05:45.334413Z","execution_failed":"2025-03-19T09:35:10.567Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    "},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Generate confusion matrix\ncm = confusion_matrix(test_df[\"label\"], predicted_labels)\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=le.classes_, yticklabels=le.classes_)\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\nplt.title(\"Confusion Matrix (ClinicalBERT)\")\nplt.savefig(\"confusion_matrix.png\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-19T09:35:10.571Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\nfrom sklearn.preprocessing import label_binarize\n\n# Binarize labels\ny_test_bin = label_binarize(test_df[\"label\"], classes=range(len(le.classes_)))\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\n\nfor i in range(len(le.classes_)):\n    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], test_preds.predictions[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Plot ROC for one class (e.g., BRCA)\nplt.figure()\nplt.plot(fpr[0], tpr[0], label=f\"ROC Curve (AUC = {roc_auc[0]:.2f})\")\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"ROC Curve for BRCA Classification\")\nplt.legend()\nplt.savefig(\"roc_curve.png\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-19T09:35:10.571Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\n# Load FLAN-T5 (free, small version)\nflan_tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\nflan_model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-19T09:35:10.572Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def flant5_few_shot_prompt(text, examples):\n    prompt = f\"\"\"\n    Classify this pathology report into one of these cancer types: {', '.join(le.classes_)}.\n    Examples:\n    {examples}\n    Report: {text}\n    Label: \"\"\"\n    return prompt\n\n# Prepare 3 examples\nexamples = []\nfor _, row in train_df.sample(3).iterrows():\n    examples.append(f\"Report: {row['clean_text']}\\nLabel: {row['cancer_type']}\\n\")\nexamples = \"\\n\".join(examples)\n\n# Generate predictions for 10 test samples (for demo)\nfew_shot_preds = []\nfor text in test_df[\"clean_text\"].sample(10):\n    prompt = flant5_few_shot_prompt(text, examples)\n    inputs = flan_tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True)\n    outputs = flan_model.generate(**inputs, max_new_tokens=5)\n    pred = flan_tokenizer.decode(outputs[0], skip_special_tokens=True)\n    few_shot_preds.append(pred)\n\n# Map predictions to labels\nfew_shot_labels = [le.transform([p.strip()])[0] if p.strip() in le.classes_ else -1 for p in few_shot_preds]\n\n# Filter valid predictions\nvalid_indices = [i for i, lbl in enumerate(few_shot_labels) if lbl != -1]\nvalid_true = test_df[\"label\"].sample(10).iloc[valid_indices]\nvalid_preds = [few_shot_labels[i] for i in valid_indices]\n\n# Calculate F1\nif len(valid_true) > 0:\n    few_shot_f1 = f1_score(valid_true, valid_preds, average=\"weighted\")\n    print(f\"FLAN-T5 Few-Shot F1: {few_shot_f1:.4f}\")  # ~0.70-0.75 (manually verify)\nelse:\n    print(\"No valid predictions.\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-19T09:35:10.573Z"}},"outputs":[],"execution_count":null}]}